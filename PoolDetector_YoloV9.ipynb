{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQjdUKvQigN2"
   },
   "source": [
    "# Training YoloV9 for swimming pool detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m09A8n4djDwY"
   },
   "source": [
    "## Before you start\n",
    "\n",
    "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_5hX88yficL7",
    "outputId": "5792d475-ab15-43a3-ec71-f97bc07d7216",
    "ExecuteTime": {
     "end_time": "2024-03-21T09:45:51.447565Z",
     "start_time": "2024-03-21T09:45:51.249181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 21 10:45:51 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 551.86                 Driver Version: 551.86         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4080 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   53C    P5             13W /  106W |    1779MiB /  12282MiB |      4%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1824    C+G   ...on\\122.0.2365.92\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A      2828    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A      3820      C   ...naconda3\\envs\\PoolFinder\\python.exe      N/A      |\n",
      "|    0   N/A  N/A      4176    C+G   ....5390.0_x64__8j3eq9eme6ctt\\IGCC.exe      N/A      |\n",
      "|    0   N/A  N/A      6028    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A      8116    C+G   ...\\PyCharm 2022.3.2\\bin\\pycharm64.exe      N/A      |\n",
      "|    0   N/A  N/A     11436    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     13372    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     13400    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     14296    C+G   ...ft Office\\root\\Office16\\OUTLOOK.EXE      N/A      |\n",
      "|    0   N/A  N/A     16484    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     16856    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A     17348    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     18144    C+G   ...ejd91yc\\AdobeNotificationClient.exe      N/A      |\n",
      "|    0   N/A  N/A     18380    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A     18528    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     18572    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     20784    C+G   ... Synapse 3 Host\\Razer Synapse 3.exe      N/A      |\n",
      "|    0   N/A  N/A     20984    C+G   ...nzyj5cx40ttqa\\iCloud\\iCloudHome.exe      N/A      |\n",
      "|    0   N/A  N/A     21208    C+G   C:\\Windows\\System32\\mmgaserver.exe          N/A      |\n",
      "|    0   N/A  N/A     22684    C+G   ...yj5cx40ttqa\\iCloud\\iCloudPhotos.exe      N/A      |\n",
      "|    0   N/A  N/A     23908      C   ...naconda3\\envs\\PoolFinder\\python.exe      N/A      |\n",
      "|    0   N/A  N/A     25032    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     26204    C+G   ...aam7r\\AcrobatNotificationClient.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTprsNjHja4l"
   },
   "source": [
    "**NOTE:** To make it easier for us to manage datasets, images and models we create a `HOME` constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T09:45:51.463650Z",
     "start_time": "2024-03-21T09:45:51.450486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rowKDIT-jJ9k",
    "outputId": "cd03f6f2-ccae-407b-dc48-19890f0769f9",
    "ExecuteTime": {
     "end_time": "2024-03-21T09:45:51.479038Z",
     "start_time": "2024-03-21T09:45:51.465520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWRGGT7Zjjbq"
   },
   "source": [
    "## Clone and Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WyY-fboBLZB"
   },
   "source": [
    "**NOTE:** YOLOv9 is very new. At the moment, we recommend using a fork of the main repository. The `detect.py` script contains a bug that prevents inference. This bug is patched in the fork."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pixgo4qnjdoU",
    "outputId": "87dcdf98-01ab-4930-9661-bd66e951b013",
    "ExecuteTime": {
     "end_time": "2024-03-21T09:46:02.156828Z",
     "start_time": "2024-03-21T09:45:51.481037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov9'...\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\walra\\anaconda3\\envs\\PoolFinder\\Lib\\site-packages\\~v2'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "roboflow 1.1.24 requires opencv-python-headless==4.8.0.74, but you have opencv-python-headless 4.9.0.80 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/SkalskiP/yolov9.git\n",
    "%cd yolov9\n",
    "!pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bcx7KoNzqpgz"
   },
   "source": [
    "**NOTE:** Let's install the [`roboflow`](https://pypi.org/project/roboflow) package, which we will use to download our dataset from [Roboflow Universe](https://universe.roboflow.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TPGqlohQqgAO",
    "outputId": "4f905130-e610-4da8-f7a5-fe55dc186215",
    "ExecuteTime": {
     "end_time": "2024-03-21T09:46:09.022233Z",
     "start_time": "2024-03-21T09:46:02.159835Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\walra\\anaconda3\\envs\\PoolFinder\\Lib\\site-packages\\~-2'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "albumentations 1.4.2 requires opencv-python-headless>=4.9.0, but you have opencv-python-headless 4.8.0.74 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q roboflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8oLIkX2l2P0"
   },
   "source": [
    "## Download model weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FieRuZnB4wH"
   },
   "source": [
    "**NOTE:** In the YOLOv9 paper, versions `yolov9-s` and `yolov9-m` are also mentioned, but the weights for these models are not yet available in the YOLOv9 [repository](https://github.com/WongKinYiu/yolov9)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7fZKrxsq_td"
   },
   "source": [
    "## Authenticate and Download the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5yx2GkI2P7Q"
   },
   "source": [
    "**NOTE:** The dataset must be saved inside the `{HOME}/yolov9` directory, otherwise, the training will not succeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MyLpftfU2Q1U",
    "outputId": "6ad7f77d-1873-41b3-8dec-4daad80f3dad",
    "ExecuteTime": {
     "end_time": "2024-03-21T09:46:09.037749Z",
     "start_time": "2024-03-21T09:46:09.024232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\n"
     ]
    }
   ],
   "source": [
    "%cd {HOME}/yolov9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eosmGt89vMO1"
   },
   "source": [
    "**NOTE:** In this tutorial, I will use the [football-players-detection](https://universe.roboflow.com/roboflow-jvuqo/football-players-detection-3zvbc) dataset. Feel free to replace it with your dataset in YOLO format or use another dataset available on [Roboflow Universe](https://universe.roboflow.com). Additionally, if you plan to deploy your model to Roboflow after training, make sure you are the owner of the dataset and that no model is associated with the version of the dataset you are going to training on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4J3s_2_7p_gn",
    "outputId": "f38d2f18-e92a-4948-c30e-9403fbd55322",
    "ExecuteTime": {
     "end_time": "2024-03-21T09:46:30.258186Z",
     "start_time": "2024-03-21T09:46:09.038749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Pools-4 to yolov9:: 100%|██████████| 71240/71240 [00:14<00:00, 4831.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Pools-4 in yolov9:: 100%|██████████| 3864/3864 [00:02<00:00, 1676.27it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"xi4q0qdfQ6V8TMejqnMb\")\n",
    "project = rf.workspace(\"poolfinder\").project(\"pools-tutud\")\n",
    "version = project.version(4)\n",
    "dataset = version.download(\"yolov9\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTbGpF2IsZ24"
   },
   "source": [
    "## Train Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T09:46:30.274193Z",
     "start_time": "2024-03-21T09:46:30.260186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "num_of_gpus = torch.cuda.device_count()\n",
    "print(num_of_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N68Bdf4FsMYW",
    "outputId": "fd4c9241-830d-4596-d418-7b0b8302c2b7",
    "ExecuteTime": {
     "end_time": "2024-03-21T09:54:05.605305Z",
     "start_time": "2024-03-21T09:49:44.630294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 10:45:32.261629: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:45:33.759786: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mweights=C:\\Users\\walra\\Documents\\GitHub\\PoolFinder/weights/gelan-c.pt, cfg=models/detect/gelan-c.yaml, data=C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\Pools-4/data.yaml, hyp=hyp.scratch-high.yaml, epochs=25, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs\\train, name=exp, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=15, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "YOLOv5  1e33dbb Python-3.10.13 torch-2.2.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4080 Laptop GPU, 12282MiB)\n",
      "\n",
      "\u001B[34m\u001B[1mhyperparameters: \u001B[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, dfl=1.5, obj_pw=1.0, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n",
      "\u001B[34m\u001B[1mClearML: \u001B[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO  in ClearML\n",
      "\u001B[34m\u001B[1mComet: \u001B[0mrun 'pip install comet_ml' to automatically track and visualize YOLO  runs in Comet\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]        \n",
      "  3                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
      "  4                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]       \n",
      "  5                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
      "  6                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
      "  7                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
      "  8                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
      "  9                -1  1    656896  models.common.SPPELAN                   [512, 512, 256]               \n",
      " 10                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 11           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 12                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
      " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 14           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 15                -1  1    912640  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 1]      \n",
      " 16                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
      " 17          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
      " 18                -1  1   2988544  models.common.RepNCSPELAN4              [768, 512, 512, 256, 1]       \n",
      " 19                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
      " 20           [-1, 9]  1         0  models.common.Concat                    [1]                           \n",
      " 21                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
      " 22      [15, 18, 21]  1   5492953  models.yolo.DDetect                     [3, [256, 512, 512]]          \n",
      "gelan-c summary: 621 layers, 25439385 parameters, 25439369 gradients, 103.2 GFLOPs\n",
      "\n",
      "Transferred 931/937 items from C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\weights\\gelan-c.pt\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01) with parameter groups 154 weight(decay=0.0), 161 weight(decay=0.0005), 160 bias\n",
      "\u001B[34m\u001B[1malbumentations: \u001B[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\Pools-4\\train\\labels.cache... 1532 images, 306 backgrounds, 0 corrupt: 100%|##########| 1532/1532 00:00\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\Pools-4\\train\\labels.cache... 1532 images, 306 backgrounds, 0 corrupt: 100%|##########| 1532/1532 00:00\n",
      "\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\Pools-4\\valid\\labels.cache... 221 images, 37 backgrounds, 0 corrupt: 100%|##########| 221/221 00:00\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\Pools-4\\valid\\labels.cache... 221 images, 37 backgrounds, 0 corrupt: 100%|##########| 221/221 00:00\n",
      "2024-03-21 10:45:45.943960: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:45:47.488452: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:45:54.798414: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:45:55.814763: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:46:03.004199: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:46:03.874311: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:46:11.844796: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:46:12.722130: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:46:20.105213: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:46:21.059507: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:46:28.422229: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:46:29.475071: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:46:37.448358: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:46:38.315937: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:46:46.567677: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:46:47.400600: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:46:59.962858: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:47:00.893931: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:47:10.876158: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:47:11.991298: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:47:21.331871: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:47:22.569422: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:47:33.675625: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:47:34.689945: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:47:46.419103: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:47:48.015905: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:47:55.152125: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:47:55.811748: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:48:01.247728: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:48:01.914464: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:48:07.414561: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:48:08.083973: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Plotting labels to runs\\train\\exp3\\labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001B[1mruns\\train\\exp3\u001B[0m\n",
      "Starting training for 25 epochs...\n",
      "2024-03-21 10:48:16.690841: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:48:17.326396: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:48:22.841928: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:48:23.470341: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:48:28.838413: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:48:29.467749: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:48:34.788629: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:48:35.413857: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:48:41.199985: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:48:41.893677: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:48:47.400448: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:48:48.095930: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:48:53.664327: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:48:54.356018: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:49:00.144808: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:49:00.895655: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/96 00:00\n",
      "       0/24      10.8G      1.083      4.904      1.463         24        640:   0%|          | 0/96 00:04Exception in thread Thread-5 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\walra\\anaconda3\\envs\\PoolFinder\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\walra\\anaconda3\\envs\\PoolFinder\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\utils\\plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\utils\\plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "\n",
      "       0/24      10.8G      1.083      4.904      1.463         24        640:   1%|1         | 1/96 00:09\n",
      "       0/24      10.9G       1.29        5.2      1.415         29        640:   1%|1         | 1/96 00:10\n",
      "       0/24      10.9G       1.29        5.2      1.415         29        640:   2%|2         | 2/96 00:10Exception in thread Thread-6 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\walra\\anaconda3\\envs\\PoolFinder\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\walra\\anaconda3\\envs\\PoolFinder\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\utils\\plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\utils\\plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "\n",
      "       0/24      10.9G       1.34      5.072       1.45         40        640:   2%|2         | 2/96 00:10\n",
      "       0/24      10.9G       1.34      5.072       1.45         40        640:   3%|3         | 3/96 00:10Exception in thread Thread-7 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\walra\\anaconda3\\envs\\PoolFinder\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\walra\\anaconda3\\envs\\PoolFinder\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\utils\\plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\utils\\plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "\n",
      "       0/24      10.9G      1.371      5.376      1.438         23        640:   3%|3         | 3/96 00:10\n",
      "       0/24      10.9G      1.371      5.376      1.438         23        640:   4%|4         | 4/96 00:10\n",
      "       0/24      10.9G      1.381        5.4      1.425         27        640:   4%|4         | 4/96 00:11\n",
      "       0/24      10.9G      1.381        5.4      1.425         27        640:   5%|5         | 5/96 00:11\n",
      "       0/24      10.9G      1.362      5.433       1.41         26        640:   5%|5         | 5/96 00:11\n",
      "       0/24      10.9G      1.362      5.433       1.41         26        640:   6%|6         | 6/96 00:11\n",
      "       0/24      10.9G      1.336      5.408      1.384         43        640:   6%|6         | 6/96 00:12\n",
      "       0/24      10.9G      1.336      5.408      1.384         43        640:   7%|7         | 7/96 00:12\n",
      "       0/24      10.9G      1.343      5.364       1.39         32        640:   7%|7         | 7/96 00:12\n",
      "       0/24      10.9G      1.343      5.364       1.39         32        640:   8%|8         | 8/96 00:12\n",
      "       0/24      10.9G      1.356       5.55      1.425         15        640:   8%|8         | 8/96 00:12\n",
      "       0/24      10.9G      1.356       5.55      1.425         15        640:   9%|9         | 9/96 00:12\n",
      "       0/24      10.9G      1.375      5.543      1.423         34        640:   9%|9         | 9/96 00:13\n",
      "       0/24      10.9G      1.375      5.543      1.423         34        640:  10%|#         | 10/96 00:13\n",
      "       0/24      10.9G      1.376      5.475      1.423         51        640:  10%|#         | 10/96 00:13\n",
      "       0/24      10.9G      1.376      5.475      1.423         51        640:  11%|#1        | 11/96 00:13\n",
      "       0/24      10.9G      1.401      5.399      1.437         49        640:  11%|#1        | 11/96 00:14\n",
      "       0/24      10.9G      1.401      5.399      1.437         49        640:  12%|#2        | 12/96 00:14\n",
      "       0/24      10.9G      1.418      5.401      1.458         25        640:  12%|#2        | 12/96 00:14\n",
      "       0/24      10.9G      1.418      5.401      1.458         25        640:  14%|#3        | 13/96 00:14\n",
      "       0/24      10.9G      1.414      5.336      1.458         44        640:  14%|#3        | 13/96 00:14\n",
      "       0/24      10.9G      1.414      5.336      1.458         44        640:  15%|#4        | 14/96 00:14\n",
      "       0/24      10.9G      1.417      5.279      1.461         41        640:  15%|#4        | 14/96 00:15\n",
      "       0/24      10.9G      1.417      5.279      1.461         41        640:  16%|#5        | 15/96 00:15\n",
      "       0/24      10.9G      1.407      5.246      1.454         31        640:  16%|#5        | 15/96 00:15\n",
      "       0/24      10.9G      1.407      5.246      1.454         31        640:  17%|#6        | 16/96 00:15\n",
      "       0/24      10.9G      1.398      5.175      1.449         37        640:  17%|#6        | 16/96 00:16\n",
      "       0/24      10.9G      1.398      5.175      1.449         37        640:  18%|#7        | 17/96 00:16\n",
      "       0/24      10.9G      1.423      5.225      1.455         22        640:  18%|#7        | 17/96 00:16\n",
      "       0/24      10.9G      1.423      5.225      1.455         22        640:  19%|#8        | 18/96 00:16\n",
      "       0/24      10.9G      1.417      5.186      1.453         32        640:  19%|#8        | 18/96 00:16\n",
      "       0/24      10.9G      1.417      5.186      1.453         32        640:  20%|#9        | 19/96 00:16\n",
      "       0/24      10.9G      1.405      5.163      1.443         23        640:  20%|#9        | 19/96 00:17\n",
      "       0/24      10.9G      1.405      5.163      1.443         23        640:  21%|##        | 20/96 00:17\n",
      "       0/24      10.9G      1.409      5.124      1.444         33        640:  21%|##        | 20/96 00:17\n",
      "       0/24      10.9G      1.409      5.124      1.444         33        640:  22%|##1       | 21/96 00:17\n",
      "       0/24      10.9G      1.406      5.077      1.441         34        640:  22%|##1       | 21/96 00:18\n",
      "       0/24      10.9G      1.406      5.077      1.441         34        640:  23%|##2       | 22/96 00:18\n",
      "       0/24      10.9G      1.404      5.021      1.446         32        640:  23%|##2       | 22/96 00:19\n",
      "       0/24      10.9G      1.404      5.021      1.446         32        640:  24%|##3       | 23/96 00:19\n",
      "       0/24      10.9G      1.396      4.944      1.442         28        640:  24%|##3       | 23/96 00:20\n",
      "       0/24      10.9G      1.396      4.944      1.442         28        640:  25%|##5       | 24/96 00:20\n",
      "       0/24      10.9G        1.4      4.874      1.446         43        640:  25%|##5       | 24/96 00:21\n",
      "       0/24      10.9G        1.4      4.874      1.446         43        640:  26%|##6       | 25/96 00:21\n",
      "       0/24      10.9G      1.388      4.824      1.439         32        640:  26%|##6       | 25/96 00:22\n",
      "       0/24      10.9G      1.388      4.824      1.439         32        640:  27%|##7       | 26/96 00:22\n",
      "       0/24      10.9G      1.389      4.779       1.44         34        640:  27%|##7       | 26/96 00:23\n",
      "       0/24      10.9G      1.389      4.779       1.44         34        640:  28%|##8       | 27/96 00:23\n",
      "       0/24      10.9G      1.398      4.733      1.444         32        640:  28%|##8       | 27/96 00:23\n",
      "       0/24      10.9G      1.398      4.733      1.444         32        640:  29%|##9       | 28/96 00:23\n",
      "       0/24      10.9G      1.396      4.675      1.439         23        640:  29%|##9       | 28/96 00:24\n",
      "       0/24      10.9G      1.396      4.675      1.439         23        640:  30%|###       | 29/96 00:24\n",
      "       0/24      10.9G      1.396      4.638      1.436         55        640:  30%|###       | 29/96 00:24\n",
      "       0/24      10.9G      1.396      4.638      1.436         55        640:  31%|###1      | 30/96 00:24\n",
      "       0/24      10.9G      1.391      4.577      1.433         41        640:  31%|###1      | 30/96 00:24\n",
      "       0/24      10.9G      1.391      4.577      1.433         41        640:  32%|###2      | 31/96 00:24\n",
      "       0/24      10.9G      1.387      4.527      1.432         31        640:  32%|###2      | 31/96 00:25\n",
      "       0/24      10.9G      1.387      4.527      1.432         31        640:  33%|###3      | 32/96 00:25\n",
      "       0/24      10.9G      1.386      4.478      1.434         34        640:  33%|###3      | 32/96 00:25\n",
      "       0/24      10.9G      1.386      4.478      1.434         34        640:  34%|###4      | 33/96 00:25\n",
      "       0/24      10.9G      1.378      4.425      1.429         37        640:  34%|###4      | 33/96 00:26\n",
      "       0/24      10.9G      1.378      4.425      1.429         37        640:  35%|###5      | 34/96 00:26\n",
      "       0/24      10.9G      1.375      4.376      1.428         37        640:  35%|###5      | 34/96 00:26\n",
      "       0/24      10.9G      1.375      4.376      1.428         37        640:  36%|###6      | 35/96 00:26\n",
      "       0/24      10.9G      1.367      4.323      1.423         44        640:  36%|###6      | 35/96 00:26\n",
      "       0/24      10.9G      1.367      4.323      1.423         44        640:  38%|###7      | 36/96 00:26\n",
      "       0/24      10.9G      1.371      4.282      1.428         31        640:  38%|###7      | 36/96 00:27\n",
      "       0/24      10.9G      1.371      4.282      1.428         31        640:  39%|###8      | 37/96 00:27\n",
      "       0/24      10.9G      1.368      4.248      1.425         32        640:  39%|###8      | 37/96 00:27\n",
      "       0/24      10.9G      1.368      4.248      1.425         32        640:  40%|###9      | 38/96 00:27\n",
      "       0/24      10.9G      1.366      4.201      1.424         28        640:  40%|###9      | 38/96 00:28\n",
      "       0/24      10.9G      1.366      4.201      1.424         28        640:  41%|####      | 39/96 00:28\n",
      "       0/24      10.9G      1.364      4.151      1.423         43        640:  41%|####      | 39/96 00:28\n",
      "       0/24      10.9G      1.364      4.151      1.423         43        640:  42%|####1     | 40/96 00:28\n",
      "       0/24      10.9G      1.362      4.099      1.422         51        640:  42%|####1     | 40/96 00:29\n",
      "       0/24      10.9G      1.362      4.099      1.422         51        640:  43%|####2     | 41/96 00:29\n",
      "       0/24      10.9G       1.36      4.057      1.423         34        640:  43%|####2     | 41/96 00:29\n",
      "       0/24      10.9G       1.36      4.057      1.423         34        640:  44%|####3     | 42/96 00:29\n",
      "       0/24      10.9G       1.36      4.022      1.422         29        640:  44%|####3     | 42/96 00:30\n",
      "       0/24      10.9G       1.36      4.022      1.422         29        640:  45%|####4     | 43/96 00:30\n",
      "       0/24      10.9G      1.359      3.988      1.419         40        640:  45%|####4     | 43/96 00:30\n",
      "       0/24      10.9G      1.359      3.988      1.419         40        640:  46%|####5     | 44/96 00:30\n",
      "       0/24      10.9G       1.36      3.974      1.423         27        640:  46%|####5     | 44/96 00:31\n",
      "       0/24      10.9G       1.36      3.974      1.423         27        640:  47%|####6     | 45/96 00:31\n",
      "       0/24      10.9G      1.356      3.937       1.42         29        640:  47%|####6     | 45/96 00:31\n",
      "       0/24      10.9G      1.356      3.937       1.42         29        640:  48%|####7     | 46/96 00:31\n",
      "       0/24      10.9G      1.356      3.894      1.418         32        640:  48%|####7     | 46/96 00:32\n",
      "       0/24      10.9G      1.356      3.894      1.418         32        640:  49%|####8     | 47/96 00:32\n",
      "       0/24      10.9G      1.356      3.862      1.418         45        640:  49%|####8     | 47/96 00:32\n",
      "       0/24      10.9G      1.356      3.862      1.418         45        640:  50%|#####     | 48/96 00:32\n",
      "       0/24      10.9G      1.352      3.822      1.411         36        640:  50%|#####     | 48/96 00:32\n",
      "       0/24      10.9G      1.352      3.822      1.411         36        640:  51%|#####1    | 49/96 00:32\n",
      "       0/24      10.9G      1.345      3.788      1.407         43        640:  51%|#####1    | 49/96 00:33\n",
      "       0/24      10.9G      1.345      3.788      1.407         43        640:  52%|#####2    | 50/96 00:33\n",
      "       0/24      10.9G      1.346      3.762      1.405         29        640:  52%|#####2    | 50/96 00:33\n",
      "       0/24      10.9G      1.346      3.762      1.405         29        640:  53%|#####3    | 51/96 00:33\n",
      "       0/24      10.9G      1.347      3.739      1.404         32        640:  53%|#####3    | 51/96 00:34\n",
      "       0/24      10.9G      1.347      3.739      1.404         32        640:  54%|#####4    | 52/96 00:34\n",
      "       0/24      10.9G      1.345       3.71        1.4         37        640:  54%|#####4    | 52/96 00:34\n",
      "       0/24      10.9G      1.345       3.71        1.4         37        640:  55%|#####5    | 53/96 00:34\n",
      "       0/24      10.9G      1.341      3.676      1.396         43        640:  55%|#####5    | 53/96 00:35\n",
      "       0/24      10.9G      1.341      3.676      1.396         43        640:  56%|#####6    | 54/96 00:35\n",
      "       0/24      10.9G      1.344      3.649      1.397         38        640:  56%|#####6    | 54/96 00:35\n",
      "       0/24      10.9G      1.344      3.649      1.397         38        640:  57%|#####7    | 55/96 00:35\n",
      "       0/24      10.9G      1.346      3.627      1.399         36        640:  57%|#####7    | 55/96 00:36\n",
      "       0/24      10.9G      1.346      3.627      1.399         36        640:  58%|#####8    | 56/96 00:36\n",
      "       0/24      10.9G      1.348        3.6        1.4         33        640:  58%|#####8    | 56/96 00:36\n",
      "       0/24      10.9G      1.348        3.6        1.4         33        640:  59%|#####9    | 57/96 00:36\n",
      "       0/24      10.9G      1.347      3.574      1.399         50        640:  59%|#####9    | 57/96 00:37\n",
      "       0/24      10.9G      1.347      3.574      1.399         50        640:  60%|######    | 58/96 00:37\n",
      "       0/24      10.9G      1.345      3.562        1.4         25        640:  60%|######    | 58/96 00:38\n",
      "       0/24      10.9G      1.345      3.562        1.4         25        640:  61%|######1   | 59/96 00:38\n",
      "       0/24      10.9G       1.34      3.536      1.396         28        640:  61%|######1   | 59/96 00:39\n",
      "       0/24      10.9G       1.34      3.536      1.396         28        640:  62%|######2   | 60/96 00:39\n",
      "       0/24      10.9G      1.336       3.51      1.393         44        640:  62%|######2   | 60/96 00:39\n",
      "       0/24      10.9G      1.336       3.51      1.393         44        640:  64%|######3   | 61/96 00:39\n",
      "       0/24      10.9G      1.331      3.483       1.39         42        640:  64%|######3   | 61/96 00:40\n",
      "       0/24      10.9G      1.331      3.483       1.39         42        640:  65%|######4   | 62/96 00:40\n",
      "       0/24      10.9G      1.328      3.471      1.387         29        640:  65%|######4   | 62/96 00:40\n",
      "       0/24      10.9G      1.328      3.471      1.387         29        640:  66%|######5   | 63/96 00:40\n",
      "       0/24      10.9G      1.327      3.458      1.385         28        640:  66%|######5   | 63/96 00:41\n",
      "       0/24      10.9G      1.327      3.458      1.385         28        640:  67%|######6   | 64/96 00:41\n",
      "       0/24      10.9G      1.322      3.438      1.381         37        640:  67%|######6   | 64/96 00:42\n",
      "       0/24      10.9G      1.322      3.438      1.381         37        640:  68%|######7   | 65/96 00:42\n",
      "       0/24      10.9G      1.319      3.426      1.381         27        640:  68%|######7   | 65/96 00:42\n",
      "       0/24      10.9G      1.319      3.426      1.381         27        640:  69%|######8   | 66/96 00:42\n",
      "       0/24      10.9G      1.318      3.407      1.381         37        640:  69%|######8   | 66/96 00:43\n",
      "       0/24      10.9G      1.318      3.407      1.381         37        640:  70%|######9   | 67/96 00:43\n",
      "       0/24      10.9G      1.314      3.382      1.378         42        640:  70%|######9   | 67/96 00:43\n",
      "       0/24      10.9G      1.314      3.382      1.378         42        640:  71%|#######   | 68/96 00:43\n",
      "       0/24      10.9G      1.317      3.371       1.38         39        640:  71%|#######   | 68/96 00:44\n",
      "       0/24      10.9G      1.317      3.371       1.38         39        640:  72%|#######1  | 69/96 00:44\n",
      "       0/24      10.9G      1.317      3.355      1.382         33        640:  72%|#######1  | 69/96 00:44\n",
      "       0/24      10.9G      1.317      3.355      1.382         33        640:  73%|#######2  | 70/96 00:44\n",
      "       0/24      10.9G      1.314      3.336      1.381         34        640:  73%|#######2  | 70/96 00:45\n",
      "       0/24      10.9G      1.314      3.336      1.381         34        640:  74%|#######3  | 71/96 00:45\n",
      "       0/24      10.9G      1.311      3.316      1.378         43        640:  74%|#######3  | 71/96 00:46\n",
      "       0/24      10.9G      1.311      3.316      1.378         43        640:  75%|#######5  | 72/96 00:46\n",
      "       0/24      10.9G      1.308      3.306      1.378         31        640:  75%|#######5  | 72/96 00:46\n",
      "       0/24      10.9G      1.308      3.306      1.378         31        640:  76%|#######6  | 73/96 00:46\n",
      "       0/24      10.9G      1.308      3.288      1.376         48        640:  76%|#######6  | 73/96 00:47\n",
      "       0/24      10.9G      1.308      3.288      1.376         48        640:  77%|#######7  | 74/96 00:47\n",
      "       0/24      10.9G      1.303      3.272      1.373         33        640:  77%|#######7  | 74/96 00:47\n",
      "       0/24      10.9G      1.303      3.272      1.373         33        640:  78%|#######8  | 75/96 00:47\n",
      "       0/24      10.9G      1.301       3.26      1.373         32        640:  78%|#######8  | 75/96 00:48\n",
      "       0/24      10.9G      1.301       3.26      1.373         32        640:  79%|#######9  | 76/96 00:48\n",
      "       0/24      10.9G      1.299      3.241       1.37         43        640:  79%|#######9  | 76/96 00:48\n",
      "       0/24      10.9G      1.299      3.241       1.37         43        640:  80%|########  | 77/96 00:48\n",
      "       0/24      10.9G      1.298      3.222       1.37         25        640:  80%|########  | 77/96 00:49\n",
      "       0/24      10.9G      1.298      3.222       1.37         25        640:  81%|########1 | 78/96 00:49\n",
      "       0/24      10.9G      1.296      3.203       1.37         39        640:  81%|########1 | 78/96 00:49\n",
      "       0/24      10.9G      1.296      3.203       1.37         39        640:  82%|########2 | 79/96 00:49\n",
      "       0/24      10.9G      1.297      3.191      1.369         38        640:  82%|########2 | 79/96 00:50\n",
      "       0/24      10.9G      1.297      3.191      1.369         38        640:  83%|########3 | 80/96 00:50\n",
      "       0/24      10.9G      1.295      3.178      1.369         39        640:  83%|########3 | 80/96 00:50\n",
      "       0/24      10.9G      1.295      3.178      1.369         39        640:  84%|########4 | 81/96 00:50\n",
      "       0/24      10.9G      1.294      3.161      1.369         37        640:  84%|########4 | 81/96 00:50\n",
      "       0/24      10.9G      1.294      3.161      1.369         37        640:  85%|########5 | 82/96 00:50\n",
      "       0/24      10.9G      1.293      3.146      1.368         28        640:  85%|########5 | 82/96 00:51\n",
      "       0/24      10.9G      1.293      3.146      1.368         28        640:  86%|########6 | 83/96 00:51\n",
      "       0/24      10.9G       1.29      3.126      1.366         33        640:  86%|########6 | 83/96 00:51\n",
      "       0/24      10.9G       1.29      3.126      1.366         33        640:  88%|########7 | 84/96 00:51\n",
      "       0/24      10.9G      1.288       3.11      1.362         41        640:  88%|########7 | 84/96 00:52\n",
      "       0/24      10.9G      1.288       3.11      1.362         41        640:  89%|########8 | 85/96 00:52\n",
      "       0/24      10.9G      1.286        3.1      1.361         30        640:  89%|########8 | 85/96 00:52\n",
      "       0/24      10.9G      1.286        3.1      1.361         30        640:  90%|########9 | 86/96 00:52\n",
      "       0/24      10.9G      1.286      3.086       1.36         46        640:  90%|########9 | 86/96 00:52\n",
      "       0/24      10.9G      1.286      3.086       1.36         46        640:  91%|######### | 87/96 00:52\n",
      "       0/24      10.9G      1.284      3.074      1.359         27        640:  91%|######### | 87/96 00:53\n",
      "       0/24      10.9G      1.284      3.074      1.359         27        640:  92%|#########1| 88/96 00:53\n",
      "       0/24      10.9G      1.286      3.063      1.359         30        640:  92%|#########1| 88/96 00:53\n",
      "       0/24      10.9G      1.286      3.063      1.359         30        640:  93%|#########2| 89/96 00:53\n",
      "       0/24      10.9G      1.284      3.046      1.357         33        640:  93%|#########2| 89/96 00:54\n",
      "       0/24      10.9G      1.284      3.046      1.357         33        640:  94%|#########3| 90/96 00:54\n",
      "       0/24      10.9G      1.283      3.032      1.356         39        640:  94%|#########3| 90/96 00:54\n",
      "       0/24      10.9G      1.283      3.032      1.356         39        640:  95%|#########4| 91/96 00:54\n",
      "       0/24      10.9G      1.279      3.017      1.354         35        640:  95%|#########4| 91/96 00:54\n",
      "       0/24      10.9G      1.279      3.017      1.354         35        640:  96%|#########5| 92/96 00:54\n",
      "       0/24      10.9G      1.279      3.002      1.353         39        640:  96%|#########5| 92/96 00:55\n",
      "       0/24      10.9G      1.279      3.002      1.353         39        640:  97%|#########6| 93/96 00:55\n",
      "       0/24      10.9G      1.276      2.986      1.351         25        640:  97%|#########6| 93/96 00:55\n",
      "       0/24      10.9G      1.276      2.986      1.351         25        640:  98%|#########7| 94/96 00:55\n",
      "       0/24      10.9G      1.275      2.974       1.35         44        640:  98%|#########7| 94/96 00:56\n",
      "       0/24      10.9G      1.275      2.974       1.35         44        640:  99%|#########8| 95/96 00:56\n",
      "       0/24      10.9G       1.27      2.963      1.348         25        640:  99%|#########8| 95/96 00:56\n",
      "       0/24      10.9G       1.27      2.963      1.348         25        640: 100%|##########| 96/96 00:56\n",
      "       0/24      10.9G       1.27      2.963      1.348         25        640: 100%|##########| 96/96 00:59\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/7 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/7 00:03\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\train.py\", line 634, in <module>\n",
      "    main(opt)\n",
      "  File \"C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\train.py\", line 528, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\train.py\", line 345, in train\n",
      "    results, maps, _ = validate.run(data_dict,\n",
      "  File \"C:\\Users\\walra\\anaconda3\\envs\\PoolFinder\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\val.py\", line 201, in run\n",
      "    preds = non_max_suppression(preds,\n",
      "  File \"C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\utils\\general.py\", line 976, in non_max_suppression\n",
      "    i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS\n",
      "  File \"C:\\Users\\walra\\anaconda3\\envs\\PoolFinder\\lib\\site-packages\\torchvision\\ops\\boxes.py\", line 41, in nms\n",
      "    return torch.ops.torchvision.nms(boxes, scores, iou_threshold)\n",
      "  File \"C:\\Users\\walra\\anaconda3\\envs\\PoolFinder\\lib\\site-packages\\torch\\_ops.py\", line 755, in __call__\n",
      "    return self._op(*args, **(kwargs or {}))\n",
      "NotImplementedError: Could not run 'torchvision::nms' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'torchvision::nms' is only available for these backends: [CPU, Meta, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n",
      "\n",
      "CPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\cpu\\nms_kernel.cpp:112 [kernel]\n",
      "Meta: registered at /dev/null:440 [kernel]\n",
      "QuantizedCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\quantized\\cpu\\qnms_kernel.cpp:124 [kernel]\n",
      "BackendSelect: fallthrough registered at ..\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\n",
      "Python: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:154 [backend fallback]\n",
      "FuncTorchDynamicLayerBackMode: registered at ..\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:498 [backend fallback]\n",
      "Functionalize: registered at ..\\aten\\src\\ATen\\FunctionalizeFallbackKernel.cpp:324 [backend fallback]\n",
      "Named: registered at ..\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\n",
      "Conjugate: registered at ..\\aten\\src\\ATen\\ConjugateFallback.cpp:17 [backend fallback]\n",
      "Negative: registered at ..\\aten\\src\\ATen\\native\\NegateFallback.cpp:19 [backend fallback]\n",
      "ZeroTensor: registered at ..\\aten\\src\\ATen\\ZeroTensorFallback.cpp:86 [backend fallback]\n",
      "ADInplaceOrView: fallthrough registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:86 [backend fallback]\n",
      "AutogradOther: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:53 [backend fallback]\n",
      "AutogradCPU: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:57 [backend fallback]\n",
      "AutogradCUDA: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:65 [backend fallback]\n",
      "AutogradXLA: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:69 [backend fallback]\n",
      "AutogradMPS: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:77 [backend fallback]\n",
      "AutogradXPU: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:61 [backend fallback]\n",
      "AutogradHPU: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:90 [backend fallback]\n",
      "AutogradLazy: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:73 [backend fallback]\n",
      "AutogradMeta: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:81 [backend fallback]\n",
      "Tracer: registered at ..\\torch\\csrc\\autograd\\TraceTypeManual.cpp:297 [backend fallback]\n",
      "AutocastCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:34 [kernel]\n",
      "AutocastCUDA: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:27 [kernel]\n",
      "FuncTorchBatched: registered at ..\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:720 [backend fallback]\n",
      "BatchedNestedTensor: registered at ..\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:746 [backend fallback]\n",
      "FuncTorchVmapMode: fallthrough registered at ..\\aten\\src\\ATen\\functorch\\VmapModeRegistrations.cpp:28 [backend fallback]\n",
      "Batched: registered at ..\\aten\\src\\ATen\\LegacyBatchingRegistrations.cpp:1075 [backend fallback]\n",
      "VmapMode: fallthrough registered at ..\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\n",
      "FuncTorchGradWrapper: registered at ..\\aten\\src\\ATen\\functorch\\TensorWrapper.cpp:203 [backend fallback]\n",
      "PythonTLSSnapshot: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:162 [backend fallback]\n",
      "FuncTorchDynamicLayerFrontMode: registered at ..\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:494 [backend fallback]\n",
      "PreDispatch: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:166 [backend fallback]\n",
      "PythonDispatcher: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:158 [backend fallback]\n",
      "\n",
      "2024-03-21 10:49:57.401389: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:49:58.786329: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mweights=C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9/weights/gelan-c.pt, cfg=models/detect/gelan-c.yaml, data=C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4/data.yaml, hyp=hyp.scratch-high.yaml, epochs=25, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs\\train, name=exp, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=15, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "YOLOv5  1e33dbb Python-3.10.13 torch-2.2.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4080 Laptop GPU, 12282MiB)\n",
      "\n",
      "\u001B[34m\u001B[1mhyperparameters: \u001B[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, dfl=1.5, obj_pw=1.0, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n",
      "\u001B[34m\u001B[1mClearML: \u001B[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO  in ClearML\n",
      "\u001B[34m\u001B[1mComet: \u001B[0mrun 'pip install comet_ml' to automatically track and visualize YOLO  runs in Comet\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]        \n",
      "  3                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
      "  4                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]       \n",
      "  5                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
      "  6                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
      "  7                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
      "  8                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
      "  9                -1  1    656896  models.common.SPPELAN                   [512, 512, 256]               \n",
      " 10                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 11           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 12                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
      " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 14           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 15                -1  1    912640  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 1]      \n",
      " 16                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
      " 17          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
      " 18                -1  1   2988544  models.common.RepNCSPELAN4              [768, 512, 512, 256, 1]       \n",
      " 19                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
      " 20           [-1, 9]  1         0  models.common.Concat                    [1]                           \n",
      " 21                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
      " 22      [15, 18, 21]  1   5492953  models.yolo.DDetect                     [3, [256, 512, 512]]          \n",
      "gelan-c summary: 621 layers, 25439385 parameters, 25439369 gradients, 103.2 GFLOPs\n",
      "\n",
      "Transferred 931/937 items from C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\weights\\gelan-c.pt\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01) with parameter groups 154 weight(decay=0.0), 161 weight(decay=0.0005), 160 bias\n",
      "\u001B[34m\u001B[1malbumentations: \u001B[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\train\\labels...:   0%|          | 0/1532 00:002024-03-21 10:50:21.156954: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:21.159436: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:21.169510: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:21.175430: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:21.181261: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:21.194327: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:21.203514: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:21.209545: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:22.752980: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:22.765218: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:22.780672: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:22.787542: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:22.788356: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:22.788722: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:22.797448: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:22.824684: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\train\\labels... 1 images, 1 backgrounds, 0 corrupt:   0%|          | 1/1532 00:17\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\train\\labels... 69 images, 23 backgrounds, 0 corrupt:   5%|4         | 69/1532 00:17\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\train\\labels... 159 images, 42 backgrounds, 0 corrupt:  10%|#         | 159/1532 00:17\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\train\\labels... 250 images, 52 backgrounds, 0 corrupt:  16%|#6        | 250/1532 00:17\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\train\\labels... 339 images, 78 backgrounds, 0 corrupt:  22%|##2       | 339/1532 00:17\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\train\\labels... 439 images, 85 backgrounds, 0 corrupt:  29%|##8       | 439/1532 00:17\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\train\\labels... 545 images, 104 backgrounds, 0 corrupt:  36%|###5      | 545/1532 00:17\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\train\\labels... 655 images, 131 backgrounds, 0 corrupt:  43%|####2     | 655/1532 00:17\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\train\\labels... 755 images, 147 backgrounds, 0 corrupt:  49%|####9     | 755/1532 00:17\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\train\\labels... 871 images, 166 backgrounds, 0 corrupt:  57%|#####6    | 871/1532 00:18\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\train\\labels... 987 images, 200 backgrounds, 0 corrupt:  64%|######4   | 987/1532 00:18\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\train\\labels... 1098 images, 213 backgrounds, 0 corrupt:  72%|#######1  | 1098/1532 00:18\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\train\\labels... 1207 images, 230 backgrounds, 0 corrupt:  79%|#######8  | 1207/1532 00:18\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\train\\labels... 1315 images, 259 backgrounds, 0 corrupt:  86%|########5 | 1315/1532 00:18\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\train\\labels... 1423 images, 287 backgrounds, 0 corrupt:  93%|#########2| 1423/1532 00:18\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\train\\labels... 1530 images, 305 backgrounds, 0 corrupt: 100%|#########9| 1530/1532 00:18\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\train\\labels... 1532 images, 306 backgrounds, 0 corrupt: 100%|##########| 1532/1532 00:18\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mNew cache created: C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\train\\labels.cache\n",
      "\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\valid\\labels...:   0%|          | 0/221 00:002024-03-21 10:50:36.860592: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:36.865611: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:36.868058: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:36.869267: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:36.881800: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:36.887185: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:36.919370: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:36.924436: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:38.305404: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:38.318398: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:38.318985: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:38.324199: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:38.325005: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:38.328408: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:38.342222: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:38.351677: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\valid\\labels... 1 images, 1 backgrounds, 0 corrupt:   0%|          | 1/221 00:13\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\valid\\labels... 81 images, 19 backgrounds, 0 corrupt:  37%|###6      | 81/221 00:13\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\valid\\labels... 188 images, 33 backgrounds, 0 corrupt:  85%|########5 | 188/221 00:13\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\valid\\labels... 221 images, 37 backgrounds, 0 corrupt: 100%|##########| 221/221 00:13\n",
      "\u001B[34m\u001B[1mval: \u001B[0mNew cache created: C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\Pools-4\\valid\\labels.cache\n",
      "2024-03-21 10:50:45.589680: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:46.286710: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:51.757258: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:52.425350: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:57.808237: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:50:58.469012: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:51:03.738380: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:51:04.381222: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:51:09.685803: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:51:10.313289: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:51:15.598228: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:51:16.261467: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:51:21.403266: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:51:22.033311: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:51:27.257223: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:51:27.905089: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:51:33.280845: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:51:33.924307: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:51:39.273267: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:51:39.931938: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:51:45.145778: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:51:45.806179: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:51:51.083654: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:51:51.778957: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:51:57.003494: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:51:57.661973: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:52:03.037938: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:52:03.693275: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:52:09.065777: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:52:09.714156: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:52:14.982122: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:52:15.639250: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Plotting labels to runs\\train\\exp2\\labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001B[1mruns\\train\\exp2\u001B[0m\n",
      "Starting training for 25 epochs...\n",
      "2024-03-21 10:52:24.107531: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:52:24.774127: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:52:30.328323: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:52:30.963258: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:52:36.395720: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:52:37.041752: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:52:42.364691: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:52:43.030009: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:52:48.435645: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:52:49.079350: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:52:54.494715: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:52:55.111262: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:53:00.503420: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:53:01.154984: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:53:06.621862: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 10:53:07.270400: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/96 00:00\n",
      "       0/24      10.8G      1.083      4.904      1.463         24        640:   0%|          | 0/96 00:07Exception in thread Thread-11 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\walra\\anaconda3\\envs\\PoolFinder\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\walra\\anaconda3\\envs\\PoolFinder\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\utils\\plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\utils\\plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "\n",
      "       0/24      10.8G      1.083      4.904      1.463         24        640:   1%|1         | 1/96 00:11\n",
      "       0/24      10.9G       1.29        5.2      1.415         29        640:   1%|1         | 1/96 00:12\n",
      "       0/24      10.9G       1.29        5.2      1.415         29        640:   2%|2         | 2/96 00:12Exception in thread Thread-12 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\walra\\anaconda3\\envs\\PoolFinder\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\walra\\anaconda3\\envs\\PoolFinder\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\utils\\plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\utils\\plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "\n",
      "       0/24      10.9G       1.34      5.072       1.45         40        640:   2%|2         | 2/96 00:12\n",
      "       0/24      10.9G       1.34      5.072       1.45         40        640:   3%|3         | 3/96 00:12Exception in thread Thread-13 (plot_images):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\walra\\anaconda3\\envs\\PoolFinder\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\walra\\anaconda3\\envs\\PoolFinder\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\utils\\plots.py\", line 300, in plot_images\n",
      "    annotator.box_label(box, label, color=color)\n",
      "  File \"C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\utils\\plots.py\", line 86, in box_label\n",
      "    w, h = self.font.getsize(label)  # text width, height\n",
      "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
      "\n",
      "       0/24      10.9G      1.371      5.376      1.438         23        640:   3%|3         | 3/96 00:13\n",
      "       0/24      10.9G      1.371      5.376      1.438         23        640:   4%|4         | 4/96 00:13\n",
      "       0/24      10.9G      1.381        5.4      1.425         27        640:   4%|4         | 4/96 00:13\n",
      "       0/24      10.9G      1.381        5.4      1.425         27        640:   5%|5         | 5/96 00:13\n",
      "       0/24      10.9G      1.362      5.433       1.41         26        640:   5%|5         | 5/96 00:13\n",
      "       0/24      10.9G      1.362      5.433       1.41         26        640:   6%|6         | 6/96 00:13\n",
      "       0/24      10.9G      1.336      5.408      1.384         43        640:   6%|6         | 6/96 00:14\n",
      "       0/24      10.9G      1.336      5.408      1.384         43        640:   7%|7         | 7/96 00:14\n",
      "       0/24      10.9G      1.343      5.364       1.39         32        640:   7%|7         | 7/96 00:14\n",
      "       0/24      10.9G      1.343      5.364       1.39         32        640:   8%|8         | 8/96 00:14\n",
      "       0/24      10.9G      1.356       5.55      1.425         15        640:   8%|8         | 8/96 00:15\n",
      "       0/24      10.9G      1.356       5.55      1.425         15        640:   9%|9         | 9/96 00:15\n",
      "       0/24      10.9G      1.375      5.543      1.423         34        640:   9%|9         | 9/96 00:15\n",
      "       0/24      10.9G      1.375      5.543      1.423         34        640:  10%|#         | 10/96 00:15\n",
      "       0/24      10.9G      1.376      5.475      1.423         51        640:  10%|#         | 10/96 00:15\n",
      "       0/24      10.9G      1.376      5.475      1.423         51        640:  11%|#1        | 11/96 00:15\n",
      "       0/24      10.9G      1.401      5.399      1.437         49        640:  11%|#1        | 11/96 00:16\n",
      "       0/24      10.9G      1.401      5.399      1.437         49        640:  12%|#2        | 12/96 00:16\n",
      "       0/24      10.9G      1.418      5.401      1.458         25        640:  12%|#2        | 12/96 00:16\n",
      "       0/24      10.9G      1.418      5.401      1.458         25        640:  14%|#3        | 13/96 00:16\n",
      "       0/24      10.9G      1.414      5.336      1.458         44        640:  14%|#3        | 13/96 00:17\n",
      "       0/24      10.9G      1.414      5.336      1.458         44        640:  15%|#4        | 14/96 00:17\n",
      "       0/24      10.9G      1.417      5.279      1.461         41        640:  15%|#4        | 14/96 00:17\n",
      "       0/24      10.9G      1.417      5.279      1.461         41        640:  16%|#5        | 15/96 00:17\n",
      "       0/24      10.9G      1.407      5.246      1.454         31        640:  16%|#5        | 15/96 00:17\n",
      "       0/24      10.9G      1.407      5.246      1.454         31        640:  17%|#6        | 16/96 00:17\n",
      "       0/24      10.9G      1.398      5.175      1.449         37        640:  17%|#6        | 16/96 00:18\n",
      "       0/24      10.9G      1.398      5.175      1.449         37        640:  18%|#7        | 17/96 00:18\n",
      "       0/24      10.9G      1.423      5.225      1.455         22        640:  18%|#7        | 17/96 00:18\n",
      "       0/24      10.9G      1.423      5.225      1.455         22        640:  19%|#8        | 18/96 00:18\n",
      "       0/24      10.9G      1.417      5.186      1.453         32        640:  19%|#8        | 18/96 00:19\n",
      "       0/24      10.9G      1.417      5.186      1.453         32        640:  20%|#9        | 19/96 00:19\n",
      "       0/24      10.9G      1.405      5.163      1.443         23        640:  20%|#9        | 19/96 00:19\n",
      "       0/24      10.9G      1.405      5.163      1.443         23        640:  21%|##        | 20/96 00:19\n",
      "       0/24      10.9G      1.409      5.124      1.444         33        640:  21%|##        | 20/96 00:19\n",
      "       0/24      10.9G      1.409      5.124      1.444         33        640:  22%|##1       | 21/96 00:19\n",
      "       0/24      10.9G      1.406      5.077      1.441         34        640:  22%|##1       | 21/96 00:20\n",
      "       0/24      10.9G      1.406      5.077      1.441         34        640:  23%|##2       | 22/96 00:20\n",
      "       0/24      10.9G      1.404      5.021      1.446         32        640:  23%|##2       | 22/96 00:20\n",
      "       0/24      10.9G      1.404      5.021      1.446         32        640:  24%|##3       | 23/96 00:20\n",
      "       0/24      10.9G      1.396      4.944      1.442         28        640:  24%|##3       | 23/96 00:21\n",
      "       0/24      10.9G      1.396      4.944      1.442         28        640:  25%|##5       | 24/96 00:21\n",
      "       0/24      10.9G        1.4      4.874      1.446         43        640:  25%|##5       | 24/96 00:21\n",
      "       0/24      10.9G        1.4      4.874      1.446         43        640:  26%|##6       | 25/96 00:21\n",
      "       0/24      10.9G      1.388      4.824      1.439         32        640:  26%|##6       | 25/96 00:22\n",
      "       0/24      10.9G      1.388      4.824      1.439         32        640:  27%|##7       | 26/96 00:22\n",
      "       0/24      10.9G      1.389      4.779       1.44         34        640:  27%|##7       | 26/96 00:22\n",
      "       0/24      10.9G      1.389      4.779       1.44         34        640:  28%|##8       | 27/96 00:22\n",
      "       0/24      10.9G      1.398      4.733      1.444         32        640:  28%|##8       | 27/96 00:22\n",
      "       0/24      10.9G      1.398      4.733      1.444         32        640:  29%|##9       | 28/96 00:22\n",
      "       0/24      10.9G      1.396      4.675      1.439         23        640:  29%|##9       | 28/96 00:23\n",
      "       0/24      10.9G      1.396      4.675      1.439         23        640:  30%|###       | 29/96 00:23\n",
      "       0/24      10.9G      1.396      4.638      1.436         55        640:  30%|###       | 29/96 00:23\n",
      "       0/24      10.9G      1.396      4.638      1.436         55        640:  31%|###1      | 30/96 00:23\n",
      "       0/24      10.9G      1.391      4.577      1.433         41        640:  31%|###1      | 30/96 00:23\n",
      "       0/24      10.9G      1.391      4.577      1.433         41        640:  32%|###2      | 31/96 00:23\n",
      "       0/24      10.9G      1.387      4.527      1.432         31        640:  32%|###2      | 31/96 00:24\n",
      "       0/24      10.9G      1.387      4.527      1.432         31        640:  33%|###3      | 32/96 00:24\n",
      "       0/24      10.9G      1.386      4.478      1.434         34        640:  33%|###3      | 32/96 00:24\n",
      "       0/24      10.9G      1.386      4.478      1.434         34        640:  34%|###4      | 33/96 00:24\n",
      "       0/24      10.9G      1.378      4.425      1.429         37        640:  34%|###4      | 33/96 00:25\n",
      "       0/24      10.9G      1.378      4.425      1.429         37        640:  35%|###5      | 34/96 00:25\n",
      "       0/24      10.9G      1.375      4.376      1.428         37        640:  35%|###5      | 34/96 00:25\n",
      "       0/24      10.9G      1.375      4.376      1.428         37        640:  36%|###6      | 35/96 00:25\n",
      "       0/24      10.9G      1.367      4.323      1.423         44        640:  36%|###6      | 35/96 00:25\n",
      "       0/24      10.9G      1.367      4.323      1.423         44        640:  38%|###7      | 36/96 00:25\n",
      "       0/24      10.9G      1.371      4.282      1.428         31        640:  38%|###7      | 36/96 00:26\n",
      "       0/24      10.9G      1.371      4.282      1.428         31        640:  39%|###8      | 37/96 00:26\n",
      "       0/24      10.9G      1.368      4.248      1.425         32        640:  39%|###8      | 37/96 00:26\n",
      "       0/24      10.9G      1.368      4.248      1.425         32        640:  40%|###9      | 38/96 00:26\n",
      "       0/24      10.9G      1.366      4.201      1.424         28        640:  40%|###9      | 38/96 00:27\n",
      "       0/24      10.9G      1.366      4.201      1.424         28        640:  41%|####      | 39/96 00:27\n",
      "       0/24      10.9G      1.364      4.151      1.423         43        640:  41%|####      | 39/96 00:27\n",
      "       0/24      10.9G      1.364      4.151      1.423         43        640:  42%|####1     | 40/96 00:27\n",
      "       0/24      10.9G      1.362      4.099      1.422         51        640:  42%|####1     | 40/96 00:27\n",
      "       0/24      10.9G      1.362      4.099      1.422         51        640:  43%|####2     | 41/96 00:27\n",
      "       0/24      10.9G       1.36      4.057      1.423         34        640:  43%|####2     | 41/96 00:28\n",
      "       0/24      10.9G       1.36      4.057      1.423         34        640:  44%|####3     | 42/96 00:28\n",
      "       0/24      10.9G       1.36      4.022      1.422         29        640:  44%|####3     | 42/96 00:28\n",
      "       0/24      10.9G       1.36      4.022      1.422         29        640:  45%|####4     | 43/96 00:28\n",
      "       0/24      10.9G      1.359      3.988      1.419         40        640:  45%|####4     | 43/96 00:29\n",
      "       0/24      10.9G      1.359      3.988      1.419         40        640:  46%|####5     | 44/96 00:29\n",
      "       0/24      10.9G       1.36      3.974      1.423         27        640:  46%|####5     | 44/96 00:29\n",
      "       0/24      10.9G       1.36      3.974      1.423         27        640:  47%|####6     | 45/96 00:29\n",
      "       0/24      10.9G      1.356      3.937       1.42         29        640:  47%|####6     | 45/96 00:29\n",
      "       0/24      10.9G      1.356      3.937       1.42         29        640:  48%|####7     | 46/96 00:29\n",
      "       0/24      10.9G      1.356      3.894      1.418         32        640:  48%|####7     | 46/96 00:30\n",
      "       0/24      10.9G      1.356      3.894      1.418         32        640:  49%|####8     | 47/96 00:30\n",
      "       0/24      10.9G      1.356      3.862      1.418         45        640:  49%|####8     | 47/96 00:30\n",
      "       0/24      10.9G      1.356      3.862      1.418         45        640:  50%|#####     | 48/96 00:30\n",
      "       0/24      10.9G      1.352      3.822      1.411         36        640:  50%|#####     | 48/96 00:31\n",
      "       0/24      10.9G      1.352      3.822      1.411         36        640:  51%|#####1    | 49/96 00:31\n",
      "       0/24      10.9G      1.345      3.788      1.407         43        640:  51%|#####1    | 49/96 00:31\n",
      "       0/24      10.9G      1.345      3.788      1.407         43        640:  52%|#####2    | 50/96 00:31\n",
      "       0/24      10.9G      1.346      3.762      1.405         29        640:  52%|#####2    | 50/96 00:31\n",
      "       0/24      10.9G      1.346      3.762      1.405         29        640:  53%|#####3    | 51/96 00:31\n",
      "       0/24      10.9G      1.347      3.739      1.404         32        640:  53%|#####3    | 51/96 00:32\n",
      "       0/24      10.9G      1.347      3.739      1.404         32        640:  54%|#####4    | 52/96 00:32\n",
      "       0/24      10.9G      1.345       3.71        1.4         37        640:  54%|#####4    | 52/96 00:32\n",
      "       0/24      10.9G      1.345       3.71        1.4         37        640:  55%|#####5    | 53/96 00:32\n",
      "       0/24      10.9G      1.341      3.676      1.396         43        640:  55%|#####5    | 53/96 00:33\n",
      "       0/24      10.9G      1.341      3.676      1.396         43        640:  56%|#####6    | 54/96 00:33\n",
      "       0/24      10.9G      1.344      3.649      1.397         38        640:  56%|#####6    | 54/96 00:33\n",
      "       0/24      10.9G      1.344      3.649      1.397         38        640:  57%|#####7    | 55/96 00:33\n",
      "       0/24      10.9G      1.346      3.627      1.399         36        640:  57%|#####7    | 55/96 00:33\n",
      "       0/24      10.9G      1.346      3.627      1.399         36        640:  58%|#####8    | 56/96 00:33\n",
      "       0/24      10.9G      1.348        3.6        1.4         33        640:  58%|#####8    | 56/96 00:34\n",
      "       0/24      10.9G      1.348        3.6        1.4         33        640:  59%|#####9    | 57/96 00:34\n",
      "       0/24      10.9G      1.347      3.574      1.399         50        640:  59%|#####9    | 57/96 00:34\n",
      "       0/24      10.9G      1.347      3.574      1.399         50        640:  60%|######    | 58/96 00:34\n",
      "       0/24      10.9G      1.345      3.562        1.4         25        640:  60%|######    | 58/96 00:34\n",
      "       0/24      10.9G      1.345      3.562        1.4         25        640:  61%|######1   | 59/96 00:34\n",
      "       0/24      10.9G       1.34      3.536      1.396         28        640:  61%|######1   | 59/96 00:35\n",
      "       0/24      10.9G       1.34      3.536      1.396         28        640:  62%|######2   | 60/96 00:35\n",
      "       0/24      10.9G      1.336       3.51      1.393         44        640:  62%|######2   | 60/96 00:35\n",
      "       0/24      10.9G      1.336       3.51      1.393         44        640:  64%|######3   | 61/96 00:35\n",
      "       0/24      10.9G      1.331      3.483       1.39         42        640:  64%|######3   | 61/96 00:36\n",
      "       0/24      10.9G      1.331      3.483       1.39         42        640:  65%|######4   | 62/96 00:36\n",
      "       0/24      10.9G      1.328      3.471      1.387         29        640:  65%|######4   | 62/96 00:36\n",
      "       0/24      10.9G      1.328      3.471      1.387         29        640:  66%|######5   | 63/96 00:36\n",
      "       0/24      10.9G      1.327      3.458      1.385         28        640:  66%|######5   | 63/96 00:36\n",
      "       0/24      10.9G      1.327      3.458      1.385         28        640:  67%|######6   | 64/96 00:36\n",
      "       0/24      10.9G      1.322      3.438      1.381         37        640:  67%|######6   | 64/96 00:37\n",
      "       0/24      10.9G      1.322      3.438      1.381         37        640:  68%|######7   | 65/96 00:37\n",
      "       0/24      10.9G      1.319      3.426      1.381         27        640:  68%|######7   | 65/96 00:37\n",
      "       0/24      10.9G      1.319      3.426      1.381         27        640:  69%|######8   | 66/96 00:37\n",
      "       0/24      10.9G      1.318      3.407      1.381         37        640:  69%|######8   | 66/96 00:38\n",
      "       0/24      10.9G      1.318      3.407      1.381         37        640:  70%|######9   | 67/96 00:38\n",
      "       0/24      10.9G      1.314      3.382      1.378         42        640:  70%|######9   | 67/96 00:38\n",
      "       0/24      10.9G      1.314      3.382      1.378         42        640:  71%|#######   | 68/96 00:38\n",
      "       0/24      10.9G      1.317      3.371       1.38         39        640:  71%|#######   | 68/96 00:38\n",
      "       0/24      10.9G      1.317      3.371       1.38         39        640:  72%|#######1  | 69/96 00:38\n",
      "       0/24      10.9G      1.317      3.355      1.382         33        640:  72%|#######1  | 69/96 00:39\n",
      "       0/24      10.9G      1.317      3.355      1.382         33        640:  73%|#######2  | 70/96 00:39\n",
      "       0/24      10.9G      1.314      3.336      1.381         34        640:  73%|#######2  | 70/96 00:39\n",
      "       0/24      10.9G      1.314      3.336      1.381         34        640:  74%|#######3  | 71/96 00:39\n",
      "       0/24      10.9G      1.311      3.316      1.378         43        640:  74%|#######3  | 71/96 00:40\n",
      "       0/24      10.9G      1.311      3.316      1.378         43        640:  75%|#######5  | 72/96 00:40\n",
      "       0/24      10.9G      1.308      3.306      1.378         31        640:  75%|#######5  | 72/96 00:40\n",
      "       0/24      10.9G      1.308      3.306      1.378         31        640:  76%|#######6  | 73/96 00:40\n",
      "       0/24      10.9G      1.308      3.288      1.376         48        640:  76%|#######6  | 73/96 00:41\n",
      "       0/24      10.9G      1.308      3.288      1.376         48        640:  77%|#######7  | 74/96 00:41\n",
      "       0/24      10.9G      1.303      3.272      1.373         33        640:  77%|#######7  | 74/96 00:41\n",
      "       0/24      10.9G      1.303      3.272      1.373         33        640:  78%|#######8  | 75/96 00:41\n",
      "       0/24      10.9G      1.301       3.26      1.373         32        640:  78%|#######8  | 75/96 00:41\n",
      "       0/24      10.9G      1.301       3.26      1.373         32        640:  79%|#######9  | 76/96 00:41\n",
      "       0/24      10.9G      1.299      3.241       1.37         43        640:  79%|#######9  | 76/96 00:42\n",
      "       0/24      10.9G      1.299      3.241       1.37         43        640:  80%|########  | 77/96 00:42\n",
      "       0/24      10.9G      1.298      3.222       1.37         25        640:  80%|########  | 77/96 00:42\n",
      "       0/24      10.9G      1.298      3.222       1.37         25        640:  81%|########1 | 78/96 00:42\n",
      "       0/24      10.9G      1.296      3.203       1.37         39        640:  81%|########1 | 78/96 00:43\n",
      "       0/24      10.9G      1.296      3.203       1.37         39        640:  82%|########2 | 79/96 00:43\n",
      "       0/24      10.9G      1.297      3.191      1.369         38        640:  82%|########2 | 79/96 00:43\n",
      "       0/24      10.9G      1.297      3.191      1.369         38        640:  83%|########3 | 80/96 00:43\n",
      "       0/24      10.9G      1.295      3.178      1.369         39        640:  83%|########3 | 80/96 00:43\n",
      "       0/24      10.9G      1.295      3.178      1.369         39        640:  84%|########4 | 81/96 00:43\n",
      "       0/24      10.9G      1.294      3.161      1.369         37        640:  84%|########4 | 81/96 00:44\n",
      "       0/24      10.9G      1.294      3.161      1.369         37        640:  85%|########5 | 82/96 00:44\n",
      "       0/24      10.9G      1.293      3.146      1.368         28        640:  85%|########5 | 82/96 00:44\n",
      "       0/24      10.9G      1.293      3.146      1.368         28        640:  86%|########6 | 83/96 00:44\n",
      "       0/24      10.9G       1.29      3.126      1.366         33        640:  86%|########6 | 83/96 00:45\n",
      "       0/24      10.9G       1.29      3.126      1.366         33        640:  88%|########7 | 84/96 00:45\n",
      "       0/24      10.9G      1.288       3.11      1.362         41        640:  88%|########7 | 84/96 00:45\n",
      "       0/24      10.9G      1.288       3.11      1.362         41        640:  89%|########8 | 85/96 00:45\n",
      "       0/24      10.9G      1.286        3.1      1.361         30        640:  89%|########8 | 85/96 00:45\n",
      "       0/24      10.9G      1.286        3.1      1.361         30        640:  90%|########9 | 86/96 00:45\n",
      "       0/24      10.9G      1.286      3.086       1.36         46        640:  90%|########9 | 86/96 00:46\n",
      "       0/24      10.9G      1.286      3.086       1.36         46        640:  91%|######### | 87/96 00:46\n",
      "       0/24      10.9G      1.284      3.074      1.359         27        640:  91%|######### | 87/96 00:46\n",
      "       0/24      10.9G      1.284      3.074      1.359         27        640:  92%|#########1| 88/96 00:46\n",
      "       0/24      10.9G      1.286      3.063      1.359         30        640:  92%|#########1| 88/96 00:46\n",
      "       0/24      10.9G      1.286      3.063      1.359         30        640:  93%|#########2| 89/96 00:46\n",
      "       0/24      10.9G      1.284      3.046      1.357         33        640:  93%|#########2| 89/96 00:47\n",
      "       0/24      10.9G      1.284      3.046      1.357         33        640:  94%|#########3| 90/96 00:47\n",
      "       0/24      10.9G      1.283      3.032      1.356         39        640:  94%|#########3| 90/96 00:47\n",
      "       0/24      10.9G      1.283      3.032      1.356         39        640:  95%|#########4| 91/96 00:47\n",
      "       0/24      10.9G      1.279      3.017      1.354         35        640:  95%|#########4| 91/96 00:47\n",
      "       0/24      10.9G      1.279      3.017      1.354         35        640:  96%|#########5| 92/96 00:47\n",
      "       0/24      10.9G      1.279      3.002      1.353         39        640:  96%|#########5| 92/96 00:48\n",
      "       0/24      10.9G      1.279      3.002      1.353         39        640:  97%|#########6| 93/96 00:48\n",
      "       0/24      10.9G      1.276      2.986      1.351         25        640:  97%|#########6| 93/96 00:48\n",
      "       0/24      10.9G      1.276      2.986      1.351         25        640:  98%|#########7| 94/96 00:48\n",
      "       0/24      10.9G      1.275      2.974       1.35         44        640:  98%|#########7| 94/96 00:49\n",
      "       0/24      10.9G      1.275      2.974       1.35         44        640:  99%|#########8| 95/96 00:49\n",
      "       0/24      10.9G       1.27      2.963      1.348         25        640:  99%|#########8| 95/96 00:49\n",
      "       0/24      10.9G       1.27      2.963      1.348         25        640: 100%|##########| 96/96 00:49\n",
      "       0/24      10.9G       1.27      2.963      1.348         25        640: 100%|##########| 96/96 00:51\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/7 00:00\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/7 00:02\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\train.py\", line 634, in <module>\n",
      "    main(opt)\n",
      "  File \"C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\train.py\", line 528, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\train.py\", line 345, in train\n",
      "    results, maps, _ = validate.run(data_dict,\n",
      "  File \"C:\\Users\\walra\\anaconda3\\envs\\PoolFinder\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\val.py\", line 201, in run\n",
      "    preds = non_max_suppression(preds,\n",
      "  File \"C:\\Users\\walra\\Documents\\GitHub\\PoolFinder\\yolov9\\yolov9\\utils\\general.py\", line 976, in non_max_suppression\n",
      "    i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS\n",
      "  File \"C:\\Users\\walra\\anaconda3\\envs\\PoolFinder\\lib\\site-packages\\torchvision\\ops\\boxes.py\", line 41, in nms\n",
      "    return torch.ops.torchvision.nms(boxes, scores, iou_threshold)\n",
      "  File \"C:\\Users\\walra\\anaconda3\\envs\\PoolFinder\\lib\\site-packages\\torch\\_ops.py\", line 755, in __call__\n",
      "    return self._op(*args, **(kwargs or {}))\n",
      "NotImplementedError: Could not run 'torchvision::nms' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'torchvision::nms' is only available for these backends: [CPU, Meta, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n",
      "\n",
      "CPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\cpu\\nms_kernel.cpp:112 [kernel]\n",
      "Meta: registered at /dev/null:440 [kernel]\n",
      "QuantizedCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\quantized\\cpu\\qnms_kernel.cpp:124 [kernel]\n",
      "BackendSelect: fallthrough registered at ..\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\n",
      "Python: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:154 [backend fallback]\n",
      "FuncTorchDynamicLayerBackMode: registered at ..\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:498 [backend fallback]\n",
      "Functionalize: registered at ..\\aten\\src\\ATen\\FunctionalizeFallbackKernel.cpp:324 [backend fallback]\n",
      "Named: registered at ..\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\n",
      "Conjugate: registered at ..\\aten\\src\\ATen\\ConjugateFallback.cpp:17 [backend fallback]\n",
      "Negative: registered at ..\\aten\\src\\ATen\\native\\NegateFallback.cpp:19 [backend fallback]\n",
      "ZeroTensor: registered at ..\\aten\\src\\ATen\\ZeroTensorFallback.cpp:86 [backend fallback]\n",
      "ADInplaceOrView: fallthrough registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:86 [backend fallback]\n",
      "AutogradOther: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:53 [backend fallback]\n",
      "AutogradCPU: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:57 [backend fallback]\n",
      "AutogradCUDA: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:65 [backend fallback]\n",
      "AutogradXLA: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:69 [backend fallback]\n",
      "AutogradMPS: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:77 [backend fallback]\n",
      "AutogradXPU: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:61 [backend fallback]\n",
      "AutogradHPU: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:90 [backend fallback]\n",
      "AutogradLazy: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:73 [backend fallback]\n",
      "AutogradMeta: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:81 [backend fallback]\n",
      "Tracer: registered at ..\\torch\\csrc\\autograd\\TraceTypeManual.cpp:297 [backend fallback]\n",
      "AutocastCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:34 [kernel]\n",
      "AutocastCUDA: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:27 [kernel]\n",
      "FuncTorchBatched: registered at ..\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:720 [backend fallback]\n",
      "BatchedNestedTensor: registered at ..\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:746 [backend fallback]\n",
      "FuncTorchVmapMode: fallthrough registered at ..\\aten\\src\\ATen\\functorch\\VmapModeRegistrations.cpp:28 [backend fallback]\n",
      "Batched: registered at ..\\aten\\src\\ATen\\LegacyBatchingRegistrations.cpp:1075 [backend fallback]\n",
      "VmapMode: fallthrough registered at ..\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\n",
      "FuncTorchGradWrapper: registered at ..\\aten\\src\\ATen\\functorch\\TensorWrapper.cpp:203 [backend fallback]\n",
      "PythonTLSSnapshot: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:162 [backend fallback]\n",
      "FuncTorchDynamicLayerFrontMode: registered at ..\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:494 [backend fallback]\n",
      "PreDispatch: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:166 [backend fallback]\n",
      "PythonDispatcher: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:158 [backend fallback]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%cd {HOME}/yolov9\n",
    "\n",
    "!python train.py \\\n",
    "--batch 16 --epochs 25 --img 640 --device 0 --min-items 0 --close-mosaic 15 \\\n",
    "--data {dataset.location}/data.yaml \\\n",
    "--weights {HOME}/weights/gelan-c.pt \\\n",
    "--cfg models/detect/gelan-c.yaml \\\n",
    "--hyp hyp.scratch-high.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpCwjSUg2Mrw"
   },
   "source": [
    "## Examine Training Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHsMq7wc3bve"
   },
   "source": [
    "**NOTE:** By default, the results of each subsequent training sessions are saved in `{HOME}/yolov9/runs/train/`, in directories named `exp`, `exp2`, `exp3`, ... You can override this behavior by using the `--name` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WslwgMAW2Euc",
    "outputId": "cdc7bdf3-9a9e-4eb7-d3c5-aed74013b3fe",
    "ExecuteTime": {
     "end_time": "2024-03-21T09:46:42.166916Z",
     "start_time": "2024-03-21T09:46:42.121406Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls {HOME}/yolov9/runs/train/exp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "grirpuCstpZE",
    "outputId": "fc26e3a7-c48c-443a-9fc8-d2fdb6413362",
    "ExecuteTime": {
     "end_time": "2024-03-21T09:46:42.921824Z",
     "start_time": "2024-03-21T09:46:42.168916Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\walra\\\\Documents\\\\GitHub\\\\PoolFinder\\\\yolov9/yolov9/runs/train/exp/results.png'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mIPython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdisplay\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n\u001B[1;32m----> 3\u001B[0m \u001B[43mImage\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mHOME\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/yolov9/runs/train/exp/results.png\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwidth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PoolFinder\\lib\\site-packages\\IPython\\core\\display.py:970\u001B[0m, in \u001B[0;36mImage.__init__\u001B[1;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata, alt)\u001B[0m\n\u001B[0;32m    968\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39munconfined \u001B[38;5;241m=\u001B[39m unconfined\n\u001B[0;32m    969\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malt \u001B[38;5;241m=\u001B[39m alt\n\u001B[1;32m--> 970\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mImage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    971\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    973\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwidth \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetadata\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwidth\u001B[39m\u001B[38;5;124m'\u001B[39m, {}):\n\u001B[0;32m    974\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwidth \u001B[38;5;241m=\u001B[39m metadata[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwidth\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PoolFinder\\lib\\site-packages\\IPython\\core\\display.py:327\u001B[0m, in \u001B[0;36mDisplayObject.__init__\u001B[1;34m(self, data, url, filename, metadata)\u001B[0m\n\u001B[0;32m    324\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetadata \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    325\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetadata \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m--> 327\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    328\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_data()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PoolFinder\\lib\\site-packages\\IPython\\core\\display.py:1005\u001B[0m, in \u001B[0;36mImage.reload\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1003\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Reload the raw data from file or URL.\"\"\"\u001B[39;00m\n\u001B[0;32m   1004\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed:\n\u001B[1;32m-> 1005\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mImage\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1006\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretina:\n\u001B[0;32m   1007\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retina_shape()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PoolFinder\\lib\\site-packages\\IPython\\core\\display.py:353\u001B[0m, in \u001B[0;36mDisplayObject.reload\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    351\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfilename \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    352\u001B[0m     encoding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_read_flags \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 353\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_flags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m    354\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m    355\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39murl \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    356\u001B[0m     \u001B[38;5;66;03m# Deferred import\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\walra\\\\Documents\\\\GitHub\\\\PoolFinder\\\\yolov9/yolov9/runs/train/exp/results.png'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(filename=f\"{HOME}/yolov9/runs/train/exp/results.png\", width=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 767
    },
    "id": "qggEg7Hv1zJ6",
    "outputId": "1d08d11a-35cf-42cc-ce89-db887a0d8d8b"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(filename=f\"{HOME}/yolov9/runs/train/exp/confusion_matrix.png\", width=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Xja2fjTl32Ml",
    "outputId": "e7ea8a1d-0173-4305-c201-fb095c711c51",
    "ExecuteTime": {
     "start_time": "2024-03-21T09:46:42.926829Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(filename=f\"{HOME}/yolov9/runs/train/exp/val_batch0_pred.jpg\", width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ih1rk9O_4CYG"
   },
   "source": [
    "## Validate Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XoZv8kNE4NxS",
    "outputId": "d42787a4-7721-4571-a1b1-64684516d63c",
    "ExecuteTime": {
     "start_time": "2024-03-21T09:46:42.927830Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd {HOME}/yolov9\n",
    "\n",
    "!python val.py \\\n",
    "--img 640 --batch 32 --conf 0.001 --iou 0.7 --device 0 \\\n",
    "--data {dataset.location}/data.yaml \\\n",
    "--weights {HOME}/yolov9/runs/train/exp/weights/best.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJJ5fiqT6mEq"
   },
   "source": [
    "## Inference with Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8vnrn9cwIsUs",
    "outputId": "5aeaee1b-f1fb-4af7-841a-004d6c10dba1",
    "ExecuteTime": {
     "start_time": "2024-03-21T09:46:42.928832Z"
    }
   },
   "outputs": [],
   "source": [
    "!python detect.py \\\n",
    "--img 1280 --conf 0.1 --device 0 \\\n",
    "--weights {HOME}/yolov9/runs/train/exp/weights/best.pt \\\n",
    "--source {dataset.location}/test/images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPbhTtVXtM4Q"
   },
   "source": [
    "**NOTE:** Just like behore, the inference results have been saved in the appropriate directory inside `{HOME}/yolov9/runs/detect/`. Let's examine few of those results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XoV4sGOKJPZj",
    "outputId": "b9af94cf-7e69-4948-a6c4-ea115ff411be",
    "ExecuteTime": {
     "start_time": "2024-03-21T09:46:42.929830Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for image_path in glob.glob(f'{HOME}/yolov9/runs/detect/exp/*.jpg'):\n",
    "      display(Image(filename=image_path, width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMTTVZU48DdJ"
   },
   "source": [
    "## BONUS: Deploy YOLOv9 Model with Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QoDQAk5arRfm"
   },
   "source": [
    "**NOTE:** To deploy the model and display inference results, we will need two additional packages - [`inference`](https://pypi.org/project/inference) and [`supervision`](https://pypi.org/project/supervision). Let's install and import them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xn6YWeaa8bdZ",
    "ExecuteTime": {
     "start_time": "2024-03-21T09:46:42.931831Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q inference supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4BauaNyA8wrj"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import getpass\n",
    "\n",
    "import supervision as sv\n",
    "\n",
    "from inference import get_model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wu0-mgYpskPY"
   },
   "source": [
    "**NOTE:** Before using your model in Inference, you first need to upload your weights to Roboflow Universe. Ensure to specify the correct `model_type` - `yolov9`, and that the project version matches the version of the dataset you used for training, denoted by `[1]`. In my case, it's `6`.\n",
    "\n",
    "![YOLOv9 Benchmark](https://storage.googleapis.com/com-roboflow-marketing/notebooks/examples/upload-roboflow-model.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tV-BnNU-7_4h",
    "outputId": "221953fd-3c6d-4cbc-fb5a-b4847fe4dd80"
   },
   "outputs": [],
   "source": [
    "version.deploy(model_type=\"yolov9\", model_path=f\"{HOME}/yolov9/runs/train/exp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KH30xwvAx1nb"
   },
   "source": [
    "**NOTE:** Now we can download our model anywhere using the assigned `model_id` denoted by `[2]`. In my case `football-players-detection-3zvbc/6`. To download the model you will need your [`ROBOFLOW_API_KEY`](https://docs.roboflow.com/api-reference/authentication).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bAB-5ZMM87w3",
    "outputId": "3eb4a88c-0fb5-4dcb-a352-ead516e255a0",
    "ExecuteTime": {
     "start_time": "2024-03-21T09:46:42.935831Z"
    }
   },
   "outputs": [],
   "source": [
    "ROBOFLOW_API_KEY = getpass.getpass()\n",
    "\n",
    "model = get_model(model_id=\"football-players-detection-3zvbc/8\", api_key=ROBOFLOW_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pGSLZ8Fz5qO"
   },
   "source": [
    "**NOTE:** Let's pick random image from our test subset and detect objects using newly fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aes2oRxi9Kpv",
    "ExecuteTime": {
     "start_time": "2024-03-21T09:46:42.937831Z"
    }
   },
   "outputs": [],
   "source": [
    "image_paths = sv.list_files_with_extensions(\n",
    "    directory=f\"{dataset.location}/test/images\",\n",
    "    extensions=['png', 'jpg', 'jpeg']\n",
    ")\n",
    "image_path = random.choice(image_paths)\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "result = model.infer(image, confidence=0.1)[0]\n",
    "detections = sv.Detections.from_inference(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8Xdr3Vp1uir"
   },
   "source": [
    "**NOTE:** Finally, let's use supervision and [annotate](https://supervision.roboflow.com/develop/annotators/) our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "id": "Kq0BKx1_-kAy",
    "outputId": "cf68a6d0-4d0c-45ae-be58-633d2af6703a",
    "ExecuteTime": {
     "start_time": "2024-03-21T09:46:42.938833Z"
    }
   },
   "outputs": [],
   "source": [
    "label_annotator = sv.LabelAnnotator(text_color=sv.Color.BLACK)\n",
    "bounding_box_annotator = sv.BoundingBoxAnnotator()\n",
    "\n",
    "annotated_image = image.copy()\n",
    "annotated_image = bounding_box_annotator.annotate(scene=annotated_image, detections=detections)\n",
    "annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections)\n",
    "\n",
    "sv.plot_image(annotated_image)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
